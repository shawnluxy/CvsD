{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbors 66.6892349357\n",
      "Linear SVM 72.3087339201\n",
      "RBF SVM 69.8036560596\n",
      "Decision Tree 70.9546377793\n",
      "Random Forest 69.2620176032\n",
      "Neural Net 68.6526743399\n",
      "AdaBoost 70.9546377793\n",
      "Naive Bayes 68.1787406906\n"
     ]
    }
   ],
   "source": [
    "# This part is only for classifiers testing\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import csv\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "sift = cv2.xfeatures2d.SIFT_create(nfeatures=50)\n",
    "path = '/root/Downloads/ECSE-415/X_Train'\n",
    "path_csv = '/root/Downloads/ECSE-415/Y_Train.csv'\n",
    "\n",
    "def Classifier(features, labels, classifier):\n",
    "    (X_train, X_test, Y_train, Y_test) = train_test_split(features, labels, test_size=0.25, random_state=42)\n",
    "    classifier.fit(X_train, Y_train)\n",
    "    score = classifier.score(X_test, Y_test)\n",
    "    return score\n",
    "\n",
    "p_len = len([f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))])\n",
    "Features = []\n",
    "Descriptors = []\n",
    "Labels = []\n",
    "for i in range(0, p_len):\n",
    "    image = cv2.imread(path+\"/\"+str(i)+\".jpg\")\n",
    "    kp, des = sift.detectAndCompute(image, None)\n",
    "    Descriptors.append(des)\n",
    "\n",
    "flann_params = dict(algorithm=1, trees=5)\n",
    "matcher = cv2.FlannBasedMatcher(flann_params, {})\n",
    "bow_extract = cv2.BOWImgDescriptorExtractor(sift, matcher)\n",
    "bow_train = cv2.BOWKMeansTrainer(20)\n",
    "for des in Descriptors:\n",
    "    bow_train.add(des)\n",
    "voc = bow_train.cluster()\n",
    "bow_extract.setVocabulary(voc)\n",
    "\n",
    "for i in range(0, p_len):\n",
    "    image = cv2.imread(path+\"/\"+str(i)+\".jpg\")\n",
    "    feature = bow_extract.compute(image, sift.detect(image))\n",
    "    Features.extend(feature)\n",
    "\n",
    "\n",
    "with open(path_csv) as csvfile:\n",
    "    read = csv.reader(csvfile, delimiter=',')\n",
    "    for row in read:\n",
    "        Labels.append(row[1])\n",
    "    Labels = Labels[1:]\n",
    "\n",
    "names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "         \"Naive Bayes\"]\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(5),\n",
    "    svm.LinearSVC(),\n",
    "    SVC(gamma=2, C=1),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB()]\n",
    "\n",
    "# accuracy test for 8 different classifiers\n",
    "for name, clf in zip(names, classifiers):\n",
    "    scores = Classifier(np.array(Features), np.array(Labels), clf)\n",
    "    print name, scores*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-78ef3ba98dde>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m \u001b[0mbow_extract\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinearSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbow_extract\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-78ef3ba98dde>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(classifier)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_len1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;31m#         print(\"Extract1 for:\" + str(i))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;31m#         image = extractForeground(image)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mimage_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# This part will predict the actual Test images\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import csv\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "image_train = []\n",
    "image_test = []\n",
    "path1 = '/root/Downloads/ECSE-415/X_Train'\n",
    "path2 = '/root/Downloads/ECSE-415/X_Test'\n",
    "path3 = '/root/Downloads/ECSE-415/Y_Train.csv'\n",
    "path4 = '/root/Downloads/ECSE-415/Y_Test.csv'\n",
    "\n",
    "\n",
    "def extractForeground(image):\n",
    "    h, w, d = image.shape\n",
    "    mask = np.zeros(image.shape[:2], np.uint8)\n",
    "    bgdModel = np.zeros((1, 65), np.float64)\n",
    "    fgdModel = np.zeros((1, 65), np.float64)\n",
    "    rect = (int(h*0.1), int(h*0.1), int(w*0.9), int(h*0.9))\n",
    "    cv2.grabCut(image, mask, rect, bgdModel, fgdModel, 5, cv2.GC_INIT_WITH_RECT)\n",
    "    mask2 = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')\n",
    "    image = image * mask2[:, :, np.newaxis]\n",
    "    # plt.imshow(image), plt.colorbar(), plt.show()\n",
    "    return image\n",
    "\n",
    "\n",
    "def getBOW(path, images):\n",
    "    Descriptors = []\n",
    "    for i, image in enumerate(images):\n",
    "        kp, des = sift.detectAndCompute(image, None)\n",
    "        if des is None:\n",
    "            print(\"Empty des for \" + str(i))\n",
    "            img = cv2.imread(path + \"/\" + str(i) + \".jpg\")\n",
    "            kp, des = sift.detectAndCompute(img, None)\n",
    "        Descriptors.append(des)\n",
    "    flann_params = dict(algorithm=1, trees=5)\n",
    "    matcher = cv2.FlannBasedMatcher(flann_params, {})\n",
    "    bow_extract = cv2.BOWImgDescriptorExtractor(sift, matcher)\n",
    "    bow_train = cv2.BOWKMeansTrainer(20)\n",
    "    for i, des in enumerate(Descriptors):\n",
    "        bow_train.add(des)\n",
    "    voc = bow_train.cluster()\n",
    "    bow_extract.setVocabulary(voc)\n",
    "    return bow_extract\n",
    "\n",
    "\n",
    "def getImageFeatures(path, images, bow_extract):\n",
    "    Features = []\n",
    "    for i, image in enumerate(images):\n",
    "        feature = bow_extract.compute(image, sift.detect(image))\n",
    "        if feature is None:\n",
    "            print(\"Error for \" + str(i))\n",
    "            img = cv2.imread(path + \"/\" + str(i) + \".jpg\")\n",
    "            feature = bow_extract.compute(img, sift.detect(img))\n",
    "        Features.extend(feature)\n",
    "    return Features\n",
    "\n",
    "\n",
    "def getTrainLabels(file):\n",
    "    Labels_train = []\n",
    "    with open(file) as csvfile:\n",
    "        read = csv.reader(csvfile, delimiter=',')\n",
    "        for row in read:\n",
    "            Labels_train.append(row[1])\n",
    "    Labels_train = Labels_train[1:]\n",
    "    return np.array(Labels_train, dtype=np.int32)\n",
    "\n",
    "\n",
    "# uncomment the following if want to extract foreground image before training\n",
    "def train(classifier):\n",
    "    p_len1 = len([f for f in os.listdir(path1) if os.path.isfile(os.path.join(path1, f))])\n",
    "    p_len2 = len([f for f in os.listdir(path2) if os.path.isfile(os.path.join(path2, f))])\n",
    "    for i in range(0, p_len1):\n",
    "#         print(\"Extract1 for:\" + str(i))\n",
    "        image = cv2.imread(path1 + \"/\" + str(i) + \".jpg\")\n",
    "#         image = extractForeground(image)\n",
    "        image_train.append(image)\n",
    "    for i in range(0, p_len2):\n",
    "#         print(\"Extract2 for:\" + str(i))\n",
    "        image = cv2.imread(path2 + \"/\" + str(i) + \".jpg\")\n",
    "#         image = extractForeground(image)\n",
    "        image_test.append(image)\n",
    "\n",
    "    bow_extract = getBOW(path1, image_train)\n",
    "    Features_train = getImageFeatures(path1, image_train, bow_extract)\n",
    "    Labels_train = getTrainLabels(path3)\n",
    "\n",
    "    clf = classifier.fit(Features_train, Labels_train)\n",
    "    return bow_extract, clf\n",
    "\n",
    "\n",
    "def predict(image_test, bow_extract, clf):\n",
    "    Features_predict = getImageFeatures(path2, image_test, bow_extract)\n",
    "\n",
    "    with open(path4, 'wb') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',')\n",
    "        writer.writerow(['Image', 'Label'])\n",
    "        for i, feature in enumerate(Features_predict):\n",
    "            prediction = clf.predict(feature)\n",
    "            name = str(i) + \".jpg\"\n",
    "            writer.writerow([name, str(prediction[0])])\n",
    "\n",
    "\n",
    "bow_extract, clf = train(svm.LinearSVC())\n",
    "predict(image_test, bow_extract, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
